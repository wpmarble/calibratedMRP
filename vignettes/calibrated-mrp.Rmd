---
title: "Calibrated MRP Workflow"
output: rmarkdown::html_vignette
author: William Marble
vignette: >
  %\VignetteIndexEntry{Calibrated MRP Workflow}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup, message=FALSE, warning=FALSE}
# library(calibratedMRP)
library(fixest)
library(lubridate)
library(brms)
library(furrr)
library(forcats)
library(tidyr)
library(dplyr)
library(ggplot2)
library(modelsummary)

set.seed(1234)

# for parallel computation
future::plan("multisession", workers = 4) 
options(future.globals.maxSize = 3e3 * 1024^2) # 3GB memory for `future`

# ggplot setup
theme_set(theme_classic() + 
            theme(axis.text = element_text(size = 14), 
                  title = element_text(size = 16),
                  strip.text = element_text(size = 16),
                  legend.text = element_text(size = 14)))
```

# Introduction

In this vignette, we will estimate a calibrated multilevel regression and poststratification (MRP) model using the `calibratedMRP` package. We will use a 2022 survey of American adults to jointly model beliefs about the legitimacy of Joe Biden's presidency, perceptions of election fairness, approval of Biden's job performance, and 2020 presidential vote choice. We will then poststratify to county-level population data and calibrate our estimates to known 2020 presidential vote shares at the county level.

We'll start by loading the data and calculating the raw survey percentages. We'll compare the recalled 2020 vote to the known county-level results to illustrate the need for calibration. Then we'll fit a multivariate Bayesian hierarchical model using `brms`, generate poststratified predictions, and apply both the plug-in and full Bayes calibration procedures.

## Load Data

The file `2022-survey.rdata` includes three objects:

* `surv` is a data frame of survey data collected in fall 2022 via SurveyMonkey.
* `ps_cty` is a poststratification table with county-level population counts for cells defined by combinations of age group, education level, race, and gender. It also includes some contextual variables. County-level contextual variables include share of the population that is non-white, share Hispanic/Latino, share with a college degree, median income, and election results from 2020. Variables ending in `_z` are standardized versions of the original variables. The variables `est_n` and `est_prop` include, respectively, the estimated population count and population share in each poststratification cell, according to the 2022 American Community Survey. 
* `targets` is a data frame that includes county-level election results from 2020 which we will use as calibration targets.

It is important that the demographic and geographic variable names and levels in `surv` and `ps_cty` are identical. 

```{r load-data, cache=TRUE}
load("data/2022-survey.rdata")
glimpse(surv)
glimpse(targets)
glimpse(ps_cty)
```

## Data Prep

As data prep, we join the contextual covariates from `ps_cty` to the survey data `surv`. We also generate a few group-level variables indicating demographic interactions in both the survey data and the poststratification table. These will be included as random effects in the modeling stage of the workflow.[^1] 


[^1]: MRP performance is typically improved substantially by use of contextual covariates. 

```{r prep-survey-data}
# join contextual covariates
surv <- left_join(surv, 
                  ps_cty %>% 
                    select(countyfips, census.region, ends_with("z")) %>% 
                    distinct(),
                  by = "countyfips")

# generate demographic interactions
surv <- surv %>% 
  mutate(nonwhite = as.integer(race != "white"),
         race_educ = paste0(race, "_", educ),
         nonwhite_educ_agegrp = paste0(nonwhite, "_", educ, "_", agegrp))
ps_cty <- ps_cty %>% 
   mutate(nonwhite = as.integer(race != "white"),
         race_educ = paste0(race, "_", educ),
         nonwhite_educ_agegrp = paste0(nonwhite, "_", educ, "_", agegrp))
```

## Data Description

We are interested in three questions ask on this survey:

* `biden_legitimate`: Binary variable indicating belief that Joe Biden is the legitimate president.
* `biden_appr`: Binary variable indicating approval of Joe Biden's job performance.
* `presvote2020_twoparty`: Two-party vote choice in the 2020 presidential election, coded as a binary variable for Biden (1) vs. Trump (0).

First, we calculate raw survey means at the state level and, for the 2020 vote recall question, compare it to the known state-level results from the 2020 presidential election.
```{r raw-survey-means}
svy_means <- surv %>%
  summarise(across(c(biden_legitimate, biden_appr, presvote2020_twoparty), 
                     ~ mean(.x, na.rm = TRUE)),
            .by = state)
state_res <- ps_cty %>% 
  distinct(state, st_demvs_2020) %>% 
  rename(true_2020 = st_demvs_2020)
svy_means <- left_join(svy_means, state_res, by = "state")
```


Next, we visualize the survey estimates of the 2020 two-party vote share against the known state-level results. The grey line is the 45-degree line. There are significant discrepancies due to a combination of survey bias and sampling variance. In general, the survey substantially overrepresents Biden voters, as indicated by most points lying above the 45-degree line.

Intuitively, this suggests that we should expect the survey estimates of Biden's legitimacy and approval to be biased upwards as well, since these are correlated with vote choice.

```{r, fig.width=6, fig.height=4, echo=FALSE, message=FALSE}
ggplot(svy_means) + 
  aes(x = true_2020, y = presvote2020_twoparty, label = state) + 
  geom_abline(slope = 1, intercept = 0, colour = "grey") +
  geom_text() + 
  scale_x_continuous(labels = scales::percent, limits = c(.2, 1)) +
  scale_y_continuous(labels = scales::percent, limits = c(.2, 1)) +
  labs(x = "2020 Biden Two-Party Vote Share",
       y = "Survey Estimate",
       title = "State-Level Summary of\n2020 Biden Vote Share")
```


To see this, we can compare the correlation between the 2020 vote recall and the other two outcomes in the survey, conditional on state and other demographics. 

```{r}

m1 <- feols(biden_legitimate ~ presvote2020_twoparty + agegrp + race + gender + educ | state, data = surv) 
m2 <- feols(biden_appr       ~ presvote2020_twoparty + agegrp + race + gender + educ | state, data = surv)
modelsummary(list(`Biden Legitimate` = m1, `Biden Approval` = m2), 
             coef_map = c("presvote2020_twoparty" = "2020 Vote Recall"), 
              add_rows = tibble::tibble(
                term = c("Demographic Controls", "State FEs"),
                `m1` = c("✓", "✓"),
                `m2` = c("✓", "✓")
              ),
             gof_omit = "^(?!(Num\\.obs|R2|R2_within))")
```




# Fit Multilevel Model


## Model Overview 

The first step of the `calibratedMRP` procedure is to fit a multilevel model with a multivariate outcome. Formally, the model is specified as follows. Let $y_{i}^j \in \{0, 1\}$ indicate respondent $i$'s response to question $j$ (where $j = 1, 2, 3$ for Biden legitimacy, approval, and 2020 vote recall, respectively). Each respondent $i$ falls into a poststratification cell, denoted $c[i]$, that indicates the demographic group and location of the respondent. The geography for cell $c$ is denoted by $g[c]$.

The model is a series of logit regressions with random effects that are allowed to correlate across outcomes:

$$
\begin{align}
  y_i^j &\sim \text{Bernoulli}(\theta_{c[i]}^j) \\
  \theta_c^j &= \text{logit}^{-1}(\alpha_{g[c]} + X_{c[i]}'\beta^j  +  Z_{g[c]}' \gamma^j) \\
  (\alpha_g^1, \alpha_g^2, \alpha^3) &\sim \text{MVN}(0, \Sigma)
\end{align}
$$

The second line specifies the logit link function, where $\alpha_{g[c]}$ is a geography-level random intercept for poststratification cell $c$. The other terms are demographic predictors $X_c$ (e.g., age, race, education) and geography-level predictors $Z_{g[c]}$ (e.g., area median income, percent of the geography that is non-White). The third line specifies that the group-level intercepts are jointly normally distributed with mean 0 and covariance matrix $\Sigma$, which will be estimated. This covariance matrix is key to the calibration procedure. If the off-diagonal entries of $\Sigma$ are positive, it indicates that there is a positive correlation between the geography-level intercepts across outcomes, after accounting for demographics ($X$) and local compositional differences ($Z$).


## Construct `brms` Formula

We use the `brms` interface to the Stan modeling language to estimate the model. The `calibratedMRP` package allows you to either specify your own `brms` formula, or you can use the `fit_model()` helper function. We first show how to specify and estimate the model directly using `brms` then demonstrate how to use the `fit_model()` function to fit the same model.

We make use of two features of the `brms` modeling syntax. First, we use the `mvbind()` function to specify a multivariate response vector. Second, we use the random effects syntax `(1 | name | grouping_variable)` to specify random intercepts for each level of `grouping_variable` that are allowed correlated across outcomes.[^1] This step is extremely important, as the estimated covariance matrix is used in downstream calibration.


[^1]: See the [`brms` vignette](https://cran.r-project.org/web/packages/brms/vignettes/brms_multivariate.html) on multivariate response models for more details.

Our model includes the following predictors. 

**Individual-Level Predictors.** The individual-level predictors include gender, age group (entered as a linear predictor),  race, and education. We also include random intercepts for age group, and combinations of white/nonwhite $\times$ education $\times$ age group.[^2]

**State-Level Predictors.** The state-level predictors include the Democratic vote share in the 2020 presidential election and we include random intercepts for census region and state. 

**County-Level Predictors.** The county-level predictors include the percentage of the population that is non-White, percent Hispanic, percent with a college degree, median income, and Democratic vote share in 2020. Finally, we include a random intercept for county.


[^2]: The inclusion of a linear predictor for age group along with random effects for age group has the effect of regularizing the age effect toward a monotonic function, while allowing for nonlinearities. See [Ghitza and Gelman (2013)](https://sites.stat.columbia.edu/gelman/research/published/misterp.pdf) (p. 766) for more details on this approach.

```{r define-formula}
formula <- bf(
  mvbind(biden_legitimate, biden_appr, presvote2020_twoparty) ~

    # individual-level predictors
    gender + as.integer(agegrp) + (1 | age | agegrp) + race + educ +
    (1 | educagewhite | nonwhite_educ_agegrp) +

    # state-level predictors
    st_demvs_2016_z + (1 | censreg | census.region) + (1 | state | state) +

    # county-level predictors
    cty_pct_nonwhite_z +  cty_pct_hispanic_z +
    cty_pct_college_z + cty_med_inc_z + cty_dem2020_z +
    (1 | c | countyfips)
)

```


## Estimate Multilevel Model

The next step is to estimate the multilevel model using the `brm` function from `brms`, which compiles Stan code and estimates the model in Stan using either the `rstan` or `cmdstanr` backend. Stan provides several methods of fitting the model, including Hamiltonian Monte Carlo (HMC) and variational inference.

We specify $\text{Normal}(0, 5^2)$ priors for the fixed-effects regression coefficients and accept the following `brms` default priors for the other parameters:

$$
\begin{align*}
  \Sigma &= \text{diag}(\sigma_1, \dots, \sigma_J)' \Omega \text{diag}(\sigma_1, \dots, \sigma_J)  \\
  \sigma_j &\sim \text{Student-$t$}(3, 0, 2.5) \\
  \Omega &\sim \text{LKJ}(1) 
\end{align*}
$$
In this specification the covariance matrix $\Sigma$ is represented as a Cholesky factorization, where the standard deviations of the random effects $\sigma_j$ are given Student-$t$ priors and the correlation matrix $\Omega$ is given a uniform LKJ prior. 

Here we estimate the model using HMC, running 4 chains with 1000 iterations each. The first half of each chain will be discarded, so this will yield 2000 total posterior draws. Due to the complexity of the model we set `adapt_delta = 0.99` and `max_treedepth = 12` to ensure that the sampler converges properly.

```{r fit-model, eval=FALSE}
priors <- prior(normal(0, 5), class = b)

# Fit model
mod <- brm(formula = formula,
           data = surv,
           family = bernoulli,
           prior = priors,
           chains = 4, 
           cores = 4,
           iter = 1000,
           backend = "cmdstanr",
           adapt_delta = .99,
           max_treedepth = 12)

# save model
saveRDS(mod, file = "data/vignette_model_fit.rds")
```

```{r load-model, echo=FALSE}
mod <- readRDS("data/vignette_model_fit.rds")
```

We check some basic MCMC diagnostics to check whether the model has converged and the effective sample size of posterior draws is sufficient. 

```{r mcmc-diagnostics}
rhats <- rhat(mod)
if (max(rhats) > 1.03) rlang::warn(sprintf("%s parameters have r-hat values above 1.03", sum(rhats > 1.03)))
rstan::check_hmc_diagnostics(mod$fit)
suppressWarnings(neff <- neff_ratio(mod))
if (mean(neff) < 0.5 || min(neff) < 0.1) rlang::warn("Some parameters have low neff ratios")
```
# Generate Initial Cell-Level Estimates of Opinion

Now that we have a model relating attitudes to demographic and geographic features, the next step is to generate estimates for every cell in the poststratification table. Since we are operating in a Bayesian setting, we will generate estimates for each posterior draw. The function `generate_cell_estimates()` takes the fitted model and generates predictions for each row of the poststratification table. Specifically, it computes the posterior mean and posterior standard deviation of the average response to each outcome variable in each cell of the poststratification table. This step can be computationally intensive, so `generate_cell_estimates()` offers an optional argument `draw_ids` which allows you to specify a subset of posterior draws to use for generating predictions. 

Formally, what this function does is summarizes the posterior distribution. First, it computes an array $\tilde{\Theta}$ that has entries $\tilde{\theta}_{(m, c, j)}$ representing a draw $m$ from the posterior distribution of the share of respondents in poststratification cell $c$ who answered "yes" to question $j$. Second, it computes the cell-level posterior mean and posterior standard deviation by taking the mean and SD across draws. Finally, it appends these summaries to the original poststratification table.


```{r generate-predictions, cache=TRUE}
draw_ids <- sample(1:ndraws(mod), 100)
# Generate predictions for each poststratification cell
ps_cty <- generate_cell_estimates(mod, 
                                 ps_table = ps_cty, 
                                 draw_ids = draw_ids,
                                 se_suffix = "_se",
                                 summarize = TRUE)
ps_cty %>%  
  select(countyfips, state, agegrp, gender, educ, race, starts_with("bidenlegitimate"))
```



Let's start by visualizing the modeled relationship between the outcome and the demographic predictors in a single state. We'll start by plotting all poststratifcation cells in Pennsylvania for the Biden legitimacy outcome. Each cell represents a combination of county, age group, race, gender, and education level. 

```{r, fig.height=10, fig.width=9}
ggplot(ps_cty %>% filter(state == "PA")) + 
  aes(y = bidenlegitimate, x = as.integer(agegrp), 
      colour = ifelse(nonwhite, "non-white", "white"), weight = est_n) + 
  geom_point(aes(size = est_n, alpha = est_n), pch = 1, position = position_jitter(.25)) +
  geom_smooth(method = "lm", formula = y ~ poly(x, 2), se = FALSE) + 
  scale_y_continuous(labels = scales::percent) +
  scale_x_continuous(breaks = 1:(length(levels(ps_cty$agegrp))),  labels = levels(ps_cty$agegrp)) + 
  guides(colour = guide_legend(title = NULL)) + 
  guides(size = "none", alpha = "none") + 
  facet_grid(fct_relevel(educ, c("HS or less", "some college", "college", "postgrad")) ~ gender) + 
  theme(legend.position = "top") + 
  labs(x = "Poststratification Cell Age",
       y = "Estimated Share Believing Biden is Legitimate",
       title = "Belief in Biden Legitimacy in Pennsylvania",
       caption = "Points are sized proportional to size in population.")
```

## Generate Uncalibrated Poststratification Estimates

The final step of MRP is to poststratify to the level of interest. This involves taking a weighted average of the cell-level estimates, where the weights are proportional to the population counts in each poststratification cell. For example, suppose we wanted to estimate the share of people in Pennsylvania who believe that Joe Biden is the legitimate president. We obtain an estimate of this quantity by summing over all of the poststratification cells with the value `state == "PA"`:
$$
\begin{align}
  \hat{\theta}^{{Biden\,Legit}}_{Pa} &= \frac{1}{M}  \sum_{m=1}^{M}\sum_{c \in \text{PA}} \tilde{\theta}_{(d, c, 1)} \cdot w_c \\
\end{align}
$$
where $M$ is the total number of posterior draws and $w_c$ are weights that are proportional to the population counts in each poststratification cell $c$. We assume here that weights are normalized to sum to 1.

This step is performed by the `poststratify()` function. The function takes the poststratification table, with cell-level estimates (and, optionally, standard errors) appended, along with the names of the outcome variables to poststratify, the weights to use for poststratification, and the level of aggregation (e.g., state, county) to summarize the estimates. The function returns a data frame with the poststratified estimates and standard errors for each outcome variable at the specified level of aggregation.
 

```{r uncalib-state, fig.height=9, fig.width=6}
state_ests <- poststratify(ps_cty, 
                           outcomes = c(bidenlegitimate_uncalib, bidenappr_uncalib, presvote2020twoparty_uncalib), 
                           weight = est_prop, 
                           by = state)



ggplot(state_ests) + 
  aes(x = bidenlegitimate_uncalib, 
      y = fct_reorder(state, bidenlegitimate_uncalib)) +
  geom_point() + 
  scale_x_continuous(labels = scales::percent) + 
  labs(x = "Estimated Share Believing Biden is Legitimate",
       y = NULL,
       title = "Belief in Biden Legitimacy by State",
       subtitle = "Uncalibrated MRP Estimates")
```

The `by` argument to `poststratify()` allows you to specify multiple columns using the `tidyselect` syntax that is common to `dplyr` and other tidyverse packages. For example, let's poststatify to the state $\times$ gender level.

```{r uncalib-state-gender, fig.height=9, fig.width=6}
sg_ests <- poststratify(ps_cty, 
                        outcomes = c(bidenlegitimate_uncalib, bidenappr_uncalib, presvote2020twoparty_uncalib), 
                        weight = est_prop, 
                        by = c(state, gender))

ggplot(sg_ests) + 
  aes(x = bidenlegitimate_uncalib, 
      y = fct_reorder(state, bidenlegitimate_uncalib),
      colour = gender) +
  geom_point() + 
  scale_x_continuous(labels = scales::percent) + 
  labs(x = "Estimated Share Believing Biden is Legitimate",
       y = NULL,
       title = "Belief in Biden Legitimacy by State/Gender",
       subtitle = "Uncalibrated MRP Estimates")
```

## Calibrate Estimates


    
We then have two choices. The most flexible choice for downstream analysis is to generate a cell-level summary of the posterior distribution. We can then poststratify further to the level of interest (e.g., county, state, broad demographic group) and summarize the posterior distribution of estimates for each outcome. 


??We can use the `poststratify()` function to generate these estimates. ??

### Plug-In Uncertainty Estimation



```{r state-ests-plugin-uncertainty, fig.height=9, fig.width=6}
state_ests_uncertainty <-  poststratify(
  ps_cty, 
  outcomes = c(bidenlegitimate_uncalib, bidenappr_uncalib, presvote2020twoparty_uncalib), 
  weight = est_prop, 
  ses = TRUE,
  by = state
  )
ggplot(state_ests_uncertainty) + 
  aes(x = bidenlegitimate_uncalib, 
      xmin = bidenlegitimate_uncalib - 2 * bidenlegitimate_uncalib_se,
      xmax = bidenlegitimate_uncalib + 2 * bidenlegitimate_uncalib_se,
      y = fct_reorder(state, bidenlegitimate_uncalib)) +
  geom_point() + 
  geom_errorbarh(height = 0) + 
  scale_x_continuous(labels = scales::percent) + 
  labs(x = "Estimated Share Believing Biden is Legitimate",
       y = NULL,
       title = "Belief in Biden Legitimacy by State",
       subtitle = "Uncalibrated MRP Estimates")
```




### Full Bayesian Inference
```{r poststratify-uncalibrated, cache=TRUE}


```



<!-- # If you just want a point estimate, you can also summarize across draws here. -->
<!-- pred_plugin <- apply(pred_draws, c(2, 3), mean) -->




<!-- ### Step 2. Extract estimates of correlations between outcomes. ---------- -->
<!-- ## In the notation of the paper, this is \hat{\Sigma} from Eqn. 5-6.  -->

<!-- # The function get_re_covs() extracts draws of the covariance matrix from the  -->
<!-- # posterior.  -->
<!-- # There are two formats available -- an array version and a tidy version. -->
<!-- # The array version is used in the full Bayes calibration procedure, while the -->
<!-- # tidy version is easier to summarize and plot. -->
<!-- county_cov <- get_re_covs(mod = mod, group = "countyfips", tidy = FALSE, draw_ids = draw_ids) -->
<!-- county_cov_tidy <- get_re_covs(mod = mod, group = "countyfips", tidy = TRUE, draw_ids = draw_ids) -->


<!-- # For plug-in estimator, take the mean of the draws. -->
<!-- county_cov_plugin <- apply(county_cov, c(2,3), mean, simplify = TRUE) -->


<!-- ### Step 3. Prepare helper objects. -------------------------------------- -->

<!-- # calibration targets -->
<!-- calib_target <- res22 %>%  -->
<!--   select(countyfips, pres2020_2pty)  -->

<!-- # clean poststratification table -->
<!-- ps_table_start <- ps_cty %>%  -->
<!--   select(countyfips, est_prop) -->

<!-- # outcome names stripped of underscores (brms does this so predictions don't have them) -->
<!-- outcomes <- str_replace_all(outcomes, "_", "") -->



<!-- ## Plug-In Calibration Estimator ---------------------------------------- -->

<!-- ## Step 4, v.1. Run calibration procedure using plug-in estimators -->
<!-- ps_table_plugin <- bind_cols(ps_table_start, pred_plugin) -->

<!-- # get "realized" logit shifts for 2020 presidential vote by solving Eqn. 2 in MC'24 -->
<!-- shifts_plugin <- logit_shift(ps_table = ps_table_plugin,  -->
<!--                              pred_vars = "presvote2020twoparty", -->
<!--                              weight = est_prop,  -->
<!--                              geography = countyfips, -->
<!--                              calib_target = calib_target, -->
<!--                              calib_vars = "pres2020_2pty") -->


<!-- # add "auxiliary" logit shifts, Eqn 6. -->
<!-- shifts_plugin <- logit_shift_aux(shifts_plugin,  -->
<!--                                  shift_var = "presvote2020twoparty",  -->
<!--                                  cov = county_cov_plugin ) -->

<!-- # Calibrate predictions using estimated logit shifts -->
<!-- ps_table_plugin <- calibrate_preds(ps_table = ps_table_plugin,  -->
<!--                                    shifts = shifts_plugin, -->
<!--                                    preds = outcomes, -->
<!--                                    geography = countyfips) -->

<!-- # Aggregate/summarize the results however you want.  -->
<!-- cty_res_plugin <- poststratify(ps_table = ps_table_plugin, -->
<!--                                preds = c(all_of(outcomes), ends_with("_calib")), -->
<!--                                weight = est_prop,  -->
<!--                                by = countyfips) -->

<!-- # Confirm that calibration worked (some missing values in Alaska due to bad county-level data). -->
<!-- cty_res_plugin <- left_join(cty_res_plugin, calib_target %>% rename(truth = pres2020_2pty)) -->
<!-- plot(cty_res_plugin$presvote2020twoparty_calib ~ cty_res_plugin$truth) -->

<!-- # Compare adjusted and unadjusted estimates of Biden legitimacy.  -->
<!-- # (Doesn't actually make a big difference on average here.) -->
<!-- ggplot(cty_res_plugin) +  -->
<!--   aes(x = bidenlegitimateirt, y = bidenlegitimateirt_calib) +  -->
<!--   geom_point(size = .25) +  -->
<!--   geom_abline(slope = 1, intercept = 0, colour = "red") +  -->
<!--   geom_smooth(se = FALSE) +  -->
<!--   labs(x = "Uncalibrated MRP Estimate",  -->
<!--        y = "Calibrated MRP Estimate\n(Plug-In Estimator)", -->
<!--        title = "Belief that Biden is the legitimate president") -->


<!-- ## Full Bayes Calibration Estimator --------------------------------- -->

<!-- # Step 4, v2. full Bayes.  -->
<!-- # Run calibration procedure for each posterior draw. This is very slow, especially -->
<!-- # when there are a lot of poststratification cells. For speed gains, parallelize -->
<!-- # using furrr::future_map(). Can also just use purrr::map() or apply or a for loop. -->
<!-- out <- future_map( -->
<!--   .x = 1:length(draw_ids), -->
<!--   .progress = TRUE, -->
<!--   .f = ~ { -->
<!--      draw <- .x -->

<!--      ### add predictions to PS table -->
<!--      preds <- as_tibble(pred_draws[draw,,]) -->
<!--      ps_table <- bind_cols(ps_table_start, preds) -->

<!--      ### Calculate logit shift for governor -->
<!--      shifts <- logit_shift(ps_table = ps_table,  -->
<!--                            pred_vars = "presvote2020twoparty", -->
<!--                            weight = est_prop,  -->
<!--                            geography = countyfips, -->
<!--                            calib_target = calib_target, -->
<!--                            calib_vars = "pres2020_2pty") -->


<!--      # get auxiliary logit shifts -->
<!--      shifts <- logit_shift_aux(shifts,  -->
<!--                                shift_var = "presvote2020twoparty",  -->
<!--                                cov = county_cov[draw,,] ) -->

<!--      res <- calibrate_preds(ps_table = ps_table,  -->
<!--                             shifts = shifts, -->
<!--                             preds = outcomes, -->
<!--                             geography = countyfips) -->

<!--      res$.draw <- draw -->
<!--      res -->
<!--    }) -->


<!-- ### Step 5. Summarize results across posterior draws ----------------- -->

<!-- # To aggregate to other levels (e.g. state) do it within each draw, then  -->
<!-- # summarize across draws. E.g. to poststratify to the county level, i'll do -->
<!-- # the poststratification once for each draw then summarize across draws. -->
<!-- cty_draws <- map(out, ~ { -->
<!--   poststratify(ps_table = .x, -->
<!--                preds = c(all_of(outcomes), ends_with("_calib")), -->
<!--                weight = est_prop,  -->
<!--                by = countyfips) -->
<!-- }) -->

<!-- cty_sum <- cty_draws %>%  -->
<!--   bind_rows(.id = "draw") %>%  -->
<!--   group_by(countyfips) %>%  -->
<!--   summarise(across(-draw,  -->
<!--                    list(mean = ~ mean(.x, na.rm = TRUE), -->
<!--                         q5 = ~ quantile(.x, .05, na.rm = TRUE), -->
<!--                         q95 = ~ quantile(.x, .95, na.rm = TRUE)))) -->


<!-- # full Bayes version shows some larger differences than the plug-in estimator -->
<!-- ggplot(cty_sum) +  -->
<!--   aes(x = bidenlegitimateirt_calib_mean, y = bidenlegitimateirt_mean) +  -->
<!--   geom_point(size = .25) +  -->
<!--   geom_abline(slope = 1, intercept = 0, colour = "red") +  -->
<!--   geom_smooth(se = FALSE) +  -->
<!--   labs(x = "Uncalibrated MRP Estimate", y = "Calibrated MRP Estimate\n(Full Bayes Posterior Mean)", -->
<!--        title = "Belief that Biden is the legitimate president") -->


<!-- ``` -->
